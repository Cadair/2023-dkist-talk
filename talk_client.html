<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title></title>
<meta name="author" content=""/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="./src/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="./src/reveal.js/dist/theme/simple.css" id="theme"/>

<link rel="stylesheet" href="org.css"/>
<link rel="stylesheet" href="./src/reveal.js/plugin/highlight/monokai.css"/></head>
<body>
<div class="reveal">
<div class="slides">

<section>
<section id="slide-title" data-background="./images/vbi_blue_hires.jpg" data-background-position="top" data-background-opacity="1" class="title">
<h2 id="title">DKIST Level 1 Data and Using it in Python</h2>
<h3 style="padding-bottom: 20%;"> Stuart Mumford </h3>
<a href="https://aperio.software"><img style='float: left; width: 20%; margin-top: 100px; height: 15%;' src='images/aperio.svg'/></a><a href="https://nso.edu"><img style='float: right; width: 20%; margin-top: 60px; height: 15%; margin-right: 5%%;' src='images/NSO-logo-blue.png'/></a>
<aside class="notes">
<ul>
<li>Hello, I am Stuart Mumford and I have been working with the DKIST Data Center for nearly 7 years, primarily on the level 1 data products and <code>dkist</code> package.</li>
<li>This talk is a <i>lightning</i> fast overview of the Level 1 data products and the <code>dkist</code> Python package.</li>

</ul>

</aside>

</section>
</section>
<section>
<section id="slide-dkist" data-background="./images/dkist-exterior.jpg" data-background-opacity="0.8">
<h2 id="dkist">The Inouye Solar Telescope</h2>
<aside class="notes">
<ul>
<li>DKIST has been observing science proposals since early 2022.</li>
<li>179 datasets are now publically available.</li>

</ul>

</aside>

<div class='left' style='width: 60%; margin-left:-5em;font-weight: bolder;'>
<ul>
<li>At the HaleakalƒÅ Observatory on the island of Maui.</li>
<li>DKIST has been observing science proposals since early 2022.</li>
<li>179 datasets are now available publically.</li>
<li>Two instruments currently on-line:
<ul>
<li>Visible Spectropolarimeter (VISP)</li>
<li>Visible Broadband Imager (VBI)</li>

</ul></li>
<li>Three more instruments coming on-line:
<ul>
<li>Cryogenic Near Infrared Spectropolarimeter (Cryo-NIRSP)</li>
<li>Diffraction Limited Near Infrared Spectropolarimeter (DL-NIRSP)</li>
<li>Visible Tunable Filter (VTF)</li>

</ul></li>

</ul>
</div>

</section>
</section>
<section>
<section id="slide-python" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h2 id="python">Python Tools</h2>
<aside class="notes">
<ul>
<li><code>dkist</code> package aims to make it easy to get and load DKIST data.</li>
<li>Also a place for the community to collaborate on DKIST-specific analysis tools.</li>
<li>Provides:
<ul>
<li>Dataset search</li>
<li>Metadata download</li>
<li><code>Dataset</code> class</li>
<li>Coordinate info</li>
<li>Lazy-loading array where data is read from the FITS files.</li>
<li>Coordinate information for all pixels.</li>

</ul></li>

</ul>

</aside>

<div class='left'>

<ul>
<li><code>dkist</code> package available now on PyPI and conda-forge.</li>
<li>Developed openly on GitHub since the start.</li>
<li>A SunPy affiliated package.</li>
<li>Provides:
<ul>
<li>a plugin for SunPy's Fido to search datasets,</li>
<li>helpers for downloading FITS files with Globus,</li>
<li>A <code>Dataset</code> class based on <code>NDCube</code>.</li>

</ul></li>
<li>Uses <code>dask</code> to delay I/O of FITS files.</li>
<li>Uses <code>gWCS</code> to represent the coordinates of the whole dataset.</li>

</ul>
</div>

<div class='right'>


<div id="org6506e6c" class="figure">
<p><img src="./images/vbi_plot.png" alt="vbi_plot.png" width="80%" />
</p>
</div>


<div id="orgab6135e" class="figure">
<p><img src="./images/dkist-repo-overview.png" alt="dkist-repo-overview.png" width="80%" style="margin-top:-20px;" />
</p>
</div>

</div>

</section>
</section>
<section>
<section id="slide-datasets" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h2 id="datasets">Level One Data</h2>
<aside class="notes">
<ul>
<li>Read the slid</li>
<li>Web search "portal", allows downloads of complete datasets with Globus.</li>

</ul>

</aside>

<p>
The data holdings at the DKIST Data Center are catalogued in unique "datasets".
</p>

<blockquote >
<p>
A dataset broadly consists of a continuous set of observations taken by a single instrument, at a single pass band, with similar instrument parameters.
</p>
</blockquote>

<p>
This means that a dataset can contain a wide variety of data, such as, slit-spectra, imaging, spectropolarimetic data etc.
</p>


<div id="org6dc61af" class="figure">
<p><img src="./images/portal_results.png" alt="portal_results.png" width="100%" />
</p>
</div>

<p style="margin-top:-2em;">
<a href="https://dkist.data.nso.edu" style="margin-top:-2em;">https://dkist.data.nso.edu</a>
</p>

</section>
<section id="slide-datasets-layout" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h3 id="datasets-layout">Makeup of a dataset</h3>
<aside class="notes">
<ul>
<li>Each "calibrated exposure" goes in a FITS file.</li>
<li>We therefore end up with many FITS files per dataset, current max is 33,000 but 100s of thousands possible.</li>
<li>Each FITS file has a well documented header with information about where that file sits in the dataset array.</li>
<li>Single array requires ordering the slices in each FITS file - all this information is in the FITS headers.</li>
<li>Each dataset also includes:
<ul>
<li>An ASDF file - containing all metadata</li>
<li>A preview movie</li>
<li>A quality report pdf.</li>

</ul></li>

</ul>

</aside>

<ul>
<li>Each "calibrated exposure" is in a FITS file with a complete header.</li>
<li>Therefore each dataset contains <i>many</i> FITS files.</li>
<li>To reconstruct these files into a multi-dim array we need to <i>order</i> them.</li>
<li>Each dataset also includes: An ASDF file, a preview movie and a quality report.</li>

</ul>

</section>
<section id="slide-datasets-layout" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h3 id="datasets-layout">ASDF Files</h3>
<aside class="notes">
<ul>
<li>ASDF is a new (relative to FITS!) file format with more flexible metadata.</li>
<li>Used heavily by JWST data.</li>
<li>Powerful Python library, and initial support in C++ and IDL.</li>

</ul>

<p>
&lt;Advance fragment&gt;
</p>

<ul>
<li>The DKIST Level 1 ASDF files are <i>primarily</i> a way to distribute the metadata independantly of the data.</li>
<li><b>List of things in ASDF</b></li>
<li>This allows you to make decisions about the data you want to download based on the metadata.</li>
<li><i>With the same Python interface as interacting with the data</i>.</li>

</ul>

</aside>

<ul>
<li>Advanced Scientific Data Format (ASDF) is a new file format with more flexible metadata than FITS.</li>
<li class="fragment fade-in">DKIST ASDF files contain:
<ul>
<li>A copy of all the FITS headers for all files.</li>
<li>A copy of the inventory record which is searchable via the DKIST data search API.</li>
<li>An ordered list of filenames, and information about the array, such as dtype and shape.</li>
<li>A gWCS object representing world coordinates for the whole dataset array.</li>

</ul></li>

</ul>

</section>
</section>
<section>
<section id="slide-challenge-download" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h2 id="challenge-download">Search and Download - Data / Metadata Separation</h2>
<aside class="notes">
<ul>
<li><p>
The DKIST DC provides a search API for <i>datasets</i>.
</p>

<p>
&lt;advance slide&gt;
</p></li>

<li>This lets you search for a dataset based on metadata about the <i>whole</i> dataset, i.e. Time, IDs, Average R0.</li>
<li>But what if you want to search for a smaller unit of data?</li>
<li>The Python tools allow you to do this by working with the metadata from the ASDF file before downloading any files.</li>

</ul>

</aside>
<blockquote >
<p>
How can we make it possible to download a subset of a dataset based on metadata.
</p>
</blockquote>

<div class="org-src-container">

<pre  class="fragment (fade-in)"  ><code class="python" >&gt;&gt;&gt; Fido.search(a.dkist.Embargoed.false)
&lt;sunpy.net.fido_factory.UnifiedResponse object at 0x7f95313b5d50&gt;
Results from 1 Provider:

179 Results from the DKISTClient:

       Start Time               End Time        Instrument   Wavelength   Dataset ID ...
                                                                 nm                  ...
----------------------- ----------------------- ---------- -------------- ---------- ...
2022-06-02T17:22:50.176 2022-06-02T17:47:30.856        VBI 486.0 .. 486.0      BLKGA ...
2022-06-02T17:21:55.346 2022-06-02T17:47:58.286        VBI 393.0 .. 393.0      BJLKB ...
2022-06-02T17:22:22.754 2022-06-02T17:48:25.694        VBI 430.0 .. 430.0      BKJYA ...
                    ...                     ...        ...            ...        ... ...
2022-05-24T19:17:29.766 2022-05-24T20:05:01.446        VBI 393.0 .. 393.0      ARMVX ...
2022-05-24T18:20:24.766 2022-05-24T19:08:51.285        VBI 393.0 .. 393.0      APYJL ...
2022-05-24T19:17:02.334 2022-05-24T20:04:34.014        VBI 430.0 .. 430.0      BVYJK ...
Length = 179 rows
</code></pre>
</div>

</section>
<section id="slide-search-and-download" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h3 id="search-and-download">Search for metadata data</h3>
<aside class="notes">
<ul>
<li>One example of the utility of this metadata-first approach is filtering based on Fried Parameter.</li>
<li>The headers table contains all the FITS headers, including <code>ATMOS_R0</code>.</li>

</ul>

</aside>

<p>
The DKIST search portal and <code>dkist</code> package allow searching based on a limited subset of all metadata.
</p>

<p>
Downloading the ASDF file gives you a <i>complete</i> set of metadata for all files contained in a dataset.
</p>

<p>
This means we can decide which parts of the dataset we are interested in.
</p>

<div class='left'>
<div class="org-src-container">

<pre   ><code class="python" ># Load the dataset
ds = dkist.load_dataset("~/dkist/data/AGLKO/")

# Select headers for only frames with bad r0
bad_headers = ds.headers[ds.headers["ATMOS_R0"] &gt; 1]

# Slice up to the index of the first bad frame
sds = ds[0, :bad_headers[0]["DINDEX3"]-1, :, :]

# Download only files with good seeing, to the same directory.
sds.files.download()
</code></pre>
</div>

</div>

<div class=right'>


<div id="org07daf7b" class="figure">
<p><img src="./images/BEOGN_seeing.png" alt="BEOGN_seeing.png" width="50%" />
</p>
</div>

</div>

</section>
</section>
<section>
<section id="slide-delayed-io" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h2 id="delayed-io">Too many files - Dask and delayed IO</h2>
<aside class="notes">
<ul>
<li>How to reconstruct the data array from 1000s of files?</li>
<li>You can't have them all open at once, and you can't load them all into memory.</li>

</ul>

</aside>

<blockquote >
<p>
You think you can open 10s or 100s of thousands files at once, but you just can't.
</p>
</blockquote>

<p>
Rather than opening all the files to read the headers to reconstruct the whole array, we read the "recipe" for the array from the ASDF file.
</p>

<p>
We build an array comprised of all the arrays in the FITS files, but it's "delayed" by using <code>dask</code>, so the files are only opened on demand.
</p>


<div id="orgd6951d3" class="figure">
<p><img src="./images/dask-repr.png" alt="dask-repr.png" width="80%" />
</p>
</div>

</section>
<section id="slide-distributed" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h3 id="distributed">Delayed Compute</h3>
<aside class="notes">
<ul>
<li>Computation of the array isn't triggered until it's needed or you do it explicitly.</li>
<li>Here we do a rebinning operation and then trigger the compute.</li>
<li>Dask can schedule compute in parallel, locally, on the cloud or on HPC clusters</li>

</ul>

</aside>

<div class="org-src-container">

<pre   ><code class="python" >ds = dkist.load_dataset("~/dkist/data/AGLKO/")
rebinned_ds = ds[0, ..., :-5].rebin((10, 1, 10))
computed_data = rebinned_ds.data.compute()
</code></pre>
</div>


<div id="org368cf59" class="figure">
<p><img src="./images/dask-distributed-rebin.png" alt="dask-distributed-rebin.png" width="90%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-status" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h2 id="status">Current and Future Status</h2>
<blockquote >
<p>
<code>dkist</code> v1.0 available now! On PyPI and conda-forge.
</p>
</blockquote>

<p>
<b>Features Implemented in v1.0:</b>
</p>

<ul>
<li>Reading ASDF files into <code>Dataset</code> objects.</li>
<li>A SunPy Fido client for searching DKIST datasets.</li>
<li>Helpers for making Globus data downloads easier.</li>
<li>Extensions to the <code>NDCube</code> API for working with the collection of FITS files.</li>
<li>Internal functionality for building <code>dask</code> arrays from many FITS files.</li>

</ul>

<p>
<b>Upcoming development:</b>
</p>

<ul>
<li>Fixing use of <code>Dataset.crop</code> for slicing based on world coordinates.</li>
<li>Helpers and documentation for modifying Datasets (i.e. shifting pointing).</li>
<li>Performance improvements, on transforms and data loading.</li>
<li>Better tools for working with VBI mosaics.</li>

</ul>

</section>
</section>
<section>
<section id="slide-org7909795" data-background="./images/filt_Gband1_yellow1_1920.jpg" data-background-opacity="0.2">
<h2 id="org7909795">Thank You</h2>
<div class='left'>

<p>
Find me online:
</p>

<p>
<a href="https://cadair.com">cadair.com</a>
</p>

<p>
Thanks to everyone at NSO and the DKIST DC.
</p>

</div>

<div class='right'>


<div id="org81432a3" class="figure">
<p><img src="./images/cadair.jpg" alt="cadair.jpg" width="500px" />
</p>
</div>

</div>
</section>
</section>
</div>
</div>
<script src="./src/reveal.js/dist/reveal.js"></script>
<script src="./src/reveal.js/plugin/notes/notes.js"></script>
<script src="./src/reveal.js/plugin/highlight/highlight.js"></script>


<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
plugins: [RevealNotes, RevealHighlight],
hash: true, slideNumber: "c/t", showSlideNumber: 'speaker', center: false,
multiplex: {
    secret: null, // null if client
    id: 'e6fe5fd97d924415', // id, obtained from socket.io server
    url: 'https://reveal-multiplex.glitch.me' // Location of socket.io server
},
dependencies: [ { src: 'https://reveal-multiplex.glitch.me/socket.io/socket.io.js', async: true }, { src: 'https://reveal-multiplex.glitch.me/client.js', async: true } ]
});

</script>
</body>
</html>
