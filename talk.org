#+REVEAL_ROOT: ./src/reveal.js/
#+REVEAL_MATHJAX_URL: ./src/mathjax/es5/tex-chtml.js
#+REVEAL_HIGHLIGHT_CSS: %r/plugin/highlight/monokai.css
#+REVEAL_PLUGINS: (notes highlight multiplex)
#+REVEAL_THEME: simple
#+REVEAL_DEFAULT_SLIDE_BACKGROUND: ./images/filt_Gband1_yellow1_1920.jpg
#+REVEAL_DEFAULT_SLIDE_BACKGROUND_OPACITY: 0.2
#+OPTIONS: toc:nil
#+OPTIONS: num:nil
#+OPTIONS: reveal_title_slide:nil
#+REVEAL_EXTRA_CSS: org.css
#+REVEAL_INIT_OPTIONS: hash: true, slideNumber: "c/t", showSlideNumber: 'speaker', center: false
#+REVEAL_MULTIPLEX_ID: e6fe5fd97d924415
#+REVEAL_MULTIPLEX_SECRET: 16902089082544472937
#+REVEAL_MULTIPLEX_URL: https://reveal-multiplex.glitch.me

* DKIST Level 1 Data and Using it in Python
:PROPERTIES:
:CUSTOM_ID: title
:reveal_extra_attr: class="title"
:reveal_background: ./images/vbi_blue_hires.jpg
:reveal_background_opacity: 1
:reveal_background_position: top
:END:

#+REVEAL_HTML: <h3 style="padding-bottom: 20%;"> Stuart Mumford </h3>
#+REVEAL_HTML: <a href="https://aperio.software"><img style='float: left; width: 20%; margin-top: 100px; height: 15%;' src='images/aperio.svg'/></a><a href="https://nso.edu"><img style='float: right; width: 20%; margin-top: 60px; height: 15%; margin-right: 5%%;' src='images/NSO-logo-blue.png'/></a>
#+BEGIN_NOTES
- Hello, I am Stuart Mumford and I have been working with the DKIST Data Center for nearly 7 years, primarily on the level 1 data products and ~dkist~ package.
- This talk is a /lightning/ fast overview of the Level 1 data products and the ~dkist~ Python package.
#+END_NOTES

* The Inouye Solar Telescope
:PROPERTIES:
:CUSTOM_ID: dkist
:reveal_background: ./images/dkist-exterior.jpg
:reveal_background_opacity: 0.8
:END:
#+BEGIN_NOTES
- DKIST has been observing science proposals since early 2022.
- 179 datasets are now publically available.
#+END_NOTES

#+REVEAL_HTML: <div class='left' style='width: 60%; margin-left:-5em;font-weight: bolder;'>
- At the HaleakalƒÅ Observatory on the island of Maui.
- DKIST has been observing science proposals since early 2022.
- 179 datasets are now available publically.
- Two instruments currently on-line:
  - Visible Spectropolarimeter (VISP)
  - Visible Broadband Imager (VBI)
- Three more instruments coming on-line:
  - Cryogenic Near Infrared Spectropolarimeter (Cryo-NIRSP)
  - Diffraction Limited Near Infrared Spectropolarimeter (DL-NIRSP)
  - Visible Tunable Filter (VTF)
#+REVEAL_HTML: </div>

* Python Tools
:PROPERTIES:
:CUSTOM_ID: python
:END:
#+BEGIN_NOTES
- ~dkist~ package aims to make it easy to get and load DKIST data.
- Also a place for the community to collaborate on DKIST-specific analysis tools.
- Provides:
  - Dataset search
  - Metadata download
  - ~Dataset~ class
  - Coordinate info
  - Lazy-loading array where data is read from the FITS files.
  - Coordinate information for all pixels.
#+END_NOTES

#+REVEAL_HTML: <div class='left'>

- ~dkist~ package available now on PyPI and conda-forge.
- Developed openly on GitHub since the start.
- A SunPy affiliated package.
- Provides:
  - a plugin for SunPy's Fido to search datasets,
  - helpers for downloading FITS files with Globus,
  - A ~Dataset~ class based on ~NDCube~.
- Uses ~dask~ to delay I/O of FITS files.
- Uses ~gWCS~ to represent the coordinates of the whole dataset.
#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class='right'>

#+attr_html: :width 80%
[[./images/vbi_plot.png]]

#+attr_html: :width 80% :style margin-top:-20px;
[[./images/dkist-repo-overview.png]]

#+REVEAL_HTML: </div>

* Level One Data
:PROPERTIES:
:CUSTOM_ID: datasets
:END:
#+BEGIN_NOTES
- Read the slid
- Web search "portal", allows downloads of complete datasets with Globus.
#+END_NOTES

The data holdings at the DKIST Data Center are catalogued in unique "datasets".

#+BEGIN_QUOTE
A dataset broadly consists of a continuous set of observations taken by a single instrument, at a single pass band, with similar instrument parameters.
#+END_QUOTE

This means that a dataset can contain a wide variety of data, such as, slit-spectra, imaging, spectropolarimetic data etc.

#+attr_html: :width 100%
[[./images/portal_results.png]]

#+attr_html: :style margin-top:-2em;
[[https://dkist.data.nso.edu]]

** Makeup of a dataset
:PROPERTIES:
:CUSTOM_ID: datasets-layout
:END:
#+BEGIN_NOTES
- Each "calibrated exposure" goes in a FITS file.
- We therefore end up with many FITS files per dataset, current max is 33,000 but 100s of thousands possible.
- Each FITS file has a well documented header with information about where that file sits in the dataset array.
- Single array requires ordering the slices in each FITS file - all this information is in the FITS headers.
- Each dataset also includes:
  - An ASDF file - containing all metadata
  - A preview movie
  - A quality report pdf.
#+END_NOTES

- Each "calibrated exposure" is in a FITS file with a complete header.
- Therefore each dataset contains /many/ FITS files.
- To reconstruct these files into a multi-dim array we need to /order/ them.
- Each dataset also includes: An ASDF file, a preview movie and a quality report.

** ASDF Files
:PROPERTIES:
:CUSTOM_ID: datasets-layout
:END:
#+BEGIN_NOTES
- ASDF is a new (relative to FITS!) file format with more flexible metadata.
- Used heavily by JWST data.
- Powerful Python library, and initial support in C++ and IDL.

<Advance fragment>

- The DKIST Level 1 ASDF files are /primarily/ a way to distribute the metadata independantly of the data.
- *List of things in ASDF*
- This allows you to make decisions about the data you want to download based on the metadata.
- /With the same Python interface as interacting with the data/.

#+END_NOTES

#+ATTR_REVEAL: :frag (none fade-in)
- Advanced Scientific Data Format (ASDF) is a new file format with more flexible metadata than FITS.
- DKIST ASDF files contain:
  - A copy of all the FITS headers for all files.
  - A copy of the inventory record which is searchable via the DKIST data search API.
  - An ordered list of filenames, and information about the array, such as dtype and shape.
  - A gWCS object representing world coordinates for the whole dataset array.

* Search and Download - Data / Metadata Separation
:PROPERTIES:
:CUSTOM_ID: challenge-download
:END:
#+BEGIN_NOTES
- The DKIST DC provides a search API for /datasets/.

  <advance slide>

- This lets you search for a dataset based on metadata about the /whole/ dataset, i.e. Time, IDs, Average R0.
- But what if you want to search for a smaller unit of data?
- The Python tools allow you to do this by working with the metadata from the ASDF file before downloading any files.
#+END_NOTES
#+BEGIN_QUOTE
How can we make it possible to download a subset of a dataset based on metadata.
#+END_QUOTE

#+ATTR_REVEAL: :frag (fade-in)
#+BEGIN_SRC python
>>> Fido.search(a.dkist.Embargoed.false)
<sunpy.net.fido_factory.UnifiedResponse object at 0x7f95313b5d50>
Results from 1 Provider:

179 Results from the DKISTClient:

       Start Time               End Time        Instrument   Wavelength   Dataset ID ...
                                                                 nm                  ...
----------------------- ----------------------- ---------- -------------- ---------- ...
2022-06-02T17:22:50.176 2022-06-02T17:47:30.856        VBI 486.0 .. 486.0      BLKGA ...
2022-06-02T17:21:55.346 2022-06-02T17:47:58.286        VBI 393.0 .. 393.0      BJLKB ...
2022-06-02T17:22:22.754 2022-06-02T17:48:25.694        VBI 430.0 .. 430.0      BKJYA ...
                    ...                     ...        ...            ...        ... ...
2022-05-24T19:17:29.766 2022-05-24T20:05:01.446        VBI 393.0 .. 393.0      ARMVX ...
2022-05-24T18:20:24.766 2022-05-24T19:08:51.285        VBI 393.0 .. 393.0      APYJL ...
2022-05-24T19:17:02.334 2022-05-24T20:04:34.014        VBI 430.0 .. 430.0      BVYJK ...
Length = 179 rows
#+END_SRC

** Search for metadata data
:PROPERTIES:
:CUSTOM_ID: search-and-download
:END:
#+BEGIN_NOTES
- One example of the utility of this metadata-first approach is filtering based on Fried Parameter.
- The headers table contains all the FITS headers, including ~ATMOS_R0~.
#+END_NOTES

The DKIST search portal and ~dkist~ package allow searching based on a limited subset of all metadata.

Downloading the ASDF file gives you a /complete/ set of metadata for all files contained in a dataset.

This means we can decide which parts of the dataset we are interested in.

#+REVEAL_HTML: <div class='left'>
#+BEGIN_SRC python
# Load the dataset
ds = dkist.load_dataset("~/dkist/data/AGLKO/")

# Select headers for only frames with bad r0
bad_headers = ds.headers[ds.headers["ATMOS_R0"] > 1]

# Slice up to the index of the first bad frame
sds = ds[0, :bad_headers[0]["DINDEX3"]-1, :, :]

# Download only files with good seeing, to the same directory.
sds.files.download()
#+END_SRC

#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class=right'>

#+attr_html: :width 50%
[[./images/BEOGN_seeing.png]]

#+REVEAL_HTML: </div>

* Too many files - Dask and delayed IO
:PROPERTIES:
:CUSTOM_ID: delayed-io
:END:
#+BEGIN_NOTES
- How to reconstruct the data array from 1000s of files?
- You can't have them all open at once, and you can't load them all into memory.
#+END_NOTES

#+BEGIN_QUOTE
You think you can open 10s or 100s of thousands files at once, but you just can't.
#+END_QUOTE

Rather than opening all the files to read the headers to reconstruct the whole array, we read the "recipe" for the array from the ASDF file.

We build an array comprised of all the arrays in the FITS files, but it's "delayed" by using ~dask~, so the files are only opened on demand.

#+attr_html: :width 80%
[[./images/dask-repr.png]]

** Delayed Compute
:PROPERTIES:
:CUSTOM_ID: distributed
:END:
#+BEGIN_NOTES
- Computation of the array isn't triggered until it's needed or you do it explicitly.
- Here we do a rebinning operation and then trigger the compute.
- Dask can schedule compute in parallel, locally, on the cloud or on HPC clusters
#+END_NOTES

#+BEGIN_SRC python
ds = dkist.load_dataset("~/dkist/data/AGLKO/")
rebinned_ds = ds[0, ..., :-5].rebin((10, 1, 10))
computed_data = rebinned_ds.data.compute()
#+END_SRC

#+REVEAL_HTML: <video data-autoplay controls width=90% src="./images/dask-distributed.mp4"></video>

* Current and Future Status
:PROPERTIES:
:CUSTOM_ID: status
:END:

#+BEGIN_QUOTE
~dkist~ v1.0 available now! On PyPI and conda-forge.
#+END_QUOTE

*Features Implemented in v1.0:*

- Reading ASDF files into ~Dataset~ objects.
- A SunPy Fido client for searching DKIST datasets.
- Helpers for making Globus data downloads easier.
- Extensions to the ~NDCube~ API for working with the collection of FITS files.
- Internal functionality for building ~dask~ arrays from many FITS files.

*Upcoming development:*

- Fixing use of ~Dataset.crop~ for slicing based on world coordinates.
- Helpers and documentation for modifying Datasets (i.e. shifting pointing).
- Performance improvements, on transforms and data loading.
- Better tools for working with VBI mosaics.

* Thank You

#+REVEAL_HTML: <div class='left'>

Find me online:

 [[https://cadair.com][cadair.com]]

Thanks to everyone at NSO and the DKIST DC.

#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class='right'>

#+attr_html: :width 500px
[[./images/cadair.jpg]]

#+REVEAL_HTML: </div>
